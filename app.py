# --- 0. ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†æƒ…å ± ---
VERSION = "1.0.9"  # å°åˆ·ãƒœã‚¿ãƒ³ã‚’æœ€ä¸‹éƒ¨ã¸ç§»å‹• & å°åˆ·ç¯„å›²ã‚’çŒ®ç«‹ã¨ãƒªã‚¹ãƒˆã«é™å®š

import streamlit as st
import pandas as pd
import requests
import base64
import io
import streamlit.components.v1 as components
from datetime import datetime, timedelta

# --- 1. æ¥ç¶šè¨­å®š ---
REPO = "daimilk-lgtm/kondake"
FILE = "menu.csv"
DICT_FILE = "ingredients.csv"
HIST_FILE = "history.csv"
TOKEN = st.secrets.get("GITHUB_TOKEN")

@st.cache_data(ttl=60)
def get_menu_data():
    try:
        url = f"https://api.github.com/repos/{REPO}/contents/{FILE}"
        headers = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3+json"}
        r = requests.get(url, headers=headers)
        if r.status_code == 200:
            raw = base64.b64decode(r.json()["content"]).decode("utf-8-sig")
            df = pd.read_csv(io.StringIO(raw))
            df.columns = [c.strip() for c in df.columns]
            return df, r.json()["sha"]
    except: pass
    return None, None

@st.cache_data(ttl=60)
def get_history_data():
    try:
        url = f"https://api.github.com/repos/{REPO}/contents/{HIST_FILE}"
        headers = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3+json"}
        r = requests.get(url, headers=headers)
        if r.status_code == 200:
            raw = base64.b64decode(r.json()["content"]).decode("utf-8-sig")
            return pd.read_csv(io.StringIO(raw)), r.json()["sha"]
        else:
            return pd.DataFrame(columns=["æ—¥ä»˜", "æ›œæ—¥", "æ–™ç†å"]), None
    except:
        return pd.DataFrame(columns=["æ—¥ä»˜", "æ›œæ—¥", "æ–™ç†å"]), None

@st.cache_data(ttl=60)
def get_dict_data():
    try:
        url = f"https://raw.githubusercontent.com/{REPO}/main/{DICT_FILE}"
        return pd.read_csv(url)
    except: return None

def save_to_github(df, filename, message, current_sha=None):
    csv_content = df.to_csv(index=False, encoding="utf-8-sig")
    content_b64 = base64.b64encode(csv_content.encode("utf-8")).decode("utf-8")
    url = f"https://api.github.com/repos/{REPO}/contents/{filename}"
    headers = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3+json"}
    data = {"message": message, "content": content_b64}
    if current_sha:
        data["sha"] = current_sha
    res = requests.put(url, headers=headers, json=data)
    return res.status_code

# --- 2. ãƒ‡ã‚¶ã‚¤ãƒ³å®šç¾© ---
st.set_page_config(page_title="çŒ®ã ã‘", layout="centered")
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@100;300;400&display=swap');
    html, body, [class*="css"], p, div, select, input, label, span, .stCheckbox {
        font-family: 'Noto Sans JP', sans-serif !important;
        font-weight: 300 !important;
        color: #333;
    }
    .main-title { font-family: 'Noto Sans JP', sans-serif !important; font-weight: 100 !important; font-size: 3.2rem; text-align: center; margin: 40px 0; letter-spacing: 0.8rem; }
    .version-label { font-size: 0.7rem; color: #ccc; text-align: right; }
    .shopping-card { background: white; padding: 15px 20px; border-radius: 16px; border: 1px solid #f0f0f0; margin-bottom: 15px; box-shadow: 0 4px 12px rgba(0,0,0,0.03); }
    .category-label { font-size: 0.8rem; color: #999; margin-bottom: 5px; font-weight: 400; }
    .item-row { font-size: 1.1rem; padding: 4px 0; border-bottom: 0.5px solid #f9f9f9; }
    .preview-table { width: 100%; border-collapse: collapse; font-size: 0.9rem; margin-bottom: 20px; border-radius: 12px; overflow: hidden; border: 1px solid #eee; }
    .preview-table th { background: #fafafa; padding: 10px; border: 1px solid #eee; }
    .preview-table td { padding: 10px; border: 1px solid #eee; }
    
    /* å°åˆ·è¨­å®š: æŒ‡å®šã—ãŸã‚¯ãƒ©ã‚¹ä»¥å¤–ã‚’ã™ã¹ã¦éš ã™ */
    @media print {
        body * { visibility: hidden; }
        .print-area, .print-area * { visibility: visible; }
        .print-area { position: absolute; left: 0; top: 0; width: 100%; }
        .no-print { display: none !important; }
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="main-title">çŒ®ã ã‘</h1>', unsafe_allow_html=True)

df_menu, menu_sha = get_menu_data()
df_dict = get_dict_data()
df_hist, hist_sha = get_history_data()

tab_plan, tab_hist, tab_manage = st.tabs(["ğŸ—“ çŒ®ç«‹ä½œæˆ", "ğŸ“œ å±¥æ­´", "âš™ï¸ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç®¡ç†"])

day_labels = ["æ—¥", "æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ"]

with tab_plan:
    today = datetime.now()
    offset = (today.weekday() + 1) % 7
    default_sun = today - timedelta(days=offset)
    start_date = st.date_input("é–‹å§‹æ—¥ï¼ˆæ—¥ï¼‰", value=default_sun)

    days_tabs = st.tabs([f"{day_labels[i]}" for i in range(7)])
    cats = ["ä¸»èœ1", "ä¸»èœ2", "å‰¯èœ1", "å‰¯èœ2", "æ±ç‰©"]
    weekly_plan = {}

    for i, day_tab in enumerate(days_tabs):
        target_date = start_date + timedelta(days=i)
        d_str = target_date.strftime("%Y/%m/%d")
        w_str = day_labels[i]
        with day_tab:
            st.markdown(f"##### {d_str} ({w_str})")
            day_menu = {cat: st.selectbox(cat, ["ãªã—"] + df_menu[df_menu["ã‚«ãƒ†ã‚´ãƒªãƒ¼"] == cat]["æ–™ç†å"].tolist(), key=f"s_{i}_{cat}") for cat in cats}
            weekly_plan[d_str] = {"menu": day_menu, "weekday": w_str}

    memo = st.text_area("ãƒ¡ãƒ¢ï¼ˆè²·ã„ç‰©ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ãŸã„ã‚‚ã®ãªã©ï¼‰", placeholder="ä¾‹ï¼šåµã€ç‰›ä¹³ã€æ´—å‰¤...")

    if st.button("ç¢ºå®šã—ã¦è²·ã„ç‰©ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
        st.divider()
        new_history_entries = []
        all_ings_list = []
        rows_html = ""
        
        for d_str, data in weekly_plan.items():
            v = data["menu"]
            w_str = data["weekday"]
            for dish in v.values():
                if dish != "ãªã—":
                    new_history_entries.append({"æ—¥ä»˜": d_str, "æ›œæ—¥": w_str, "æ–™ç†å": dish})
                    ing_raw = df_menu[df_menu["æ–™ç†å"] == dish]["ææ–™"].iloc[0]
                    items = str(ing_raw).replace("ã€", ",").split(",")
                    all_ings_list.extend([x.strip() for x in items if x.strip()])
            
            m_dish = f"{v.get('ä¸»èœ1','-')} / {v.get('ä¸»èœ2','-')}".replace("ãªã—", "-")
            s_dish = f"{v.get('å‰¯èœ1','-')}, {v.get('å‰¯èœ2','-')}, {v.get('æ±ç‰©','-')}".replace("ãªã—", "-")
            rows_html += f'<tr><td>{d_str}({w_str})</td><td>{m_dish}</td><td>{s_dish}</td></tr>'

        # å±¥æ­´ä¿å­˜ãƒœã‚¿ãƒ³
        if st.button("ã“ã®å†…å®¹ã§å±¥æ­´ã‚’ä¿å­˜", type="secondary"):
            if new_history_entries:
                if "æ›œæ—¥" not in df_hist.columns: df_hist["æ›œæ—¥"] = ""
                new_hist_df = pd.concat([df_hist, pd.DataFrame(new_history_entries)], ignore_index=True).drop_duplicates()
                save_to_github(new_hist_df, HIST_FILE, "Update history", hist_sha)
                st.success("å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

        # å°åˆ·ç”¨ã‚³ãƒ³ãƒ†ãƒŠé–‹å§‹
        st.markdown('<div class="print-area">', unsafe_allow_html=True)
        
        st.markdown("### ğŸ“‹ ä»Šé€±ã®çŒ®ç«‹ãƒã‚§ãƒƒã‚¯")
        st.markdown(f'<table class="preview-table"><tr><th>æ—¥ä»˜</th><th>ä¸»èœ</th><th>å‰¯èœãƒ»æ±ç‰©</th></tr>{rows_html}</table>', unsafe_allow_html=True)

        st.markdown("### ğŸ›’ è²·ã„ç‰©ãƒªã‚¹ãƒˆ")
        if memo:
            memo_items = memo.replace("ã€", ",").replace("\n", ",").split(",")
            for m_item in memo_items:
                if m_item.strip(): all_ings_list.append(f"{m_item.strip()} (ãƒ¡ãƒ¢
