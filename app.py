import streamlit as st
import pandas as pd
import requests
import base64
import io
import streamlit.components.v1 as components
from datetime import datetime, timedelta
import re

# --- 0. ä»•æ§˜é˜²è¡›ã‚·ã‚¹ãƒ†ãƒ  (Self-Guard) ---
def validate_system_integrity():
    check_results = []
    test_date = datetime(2026, 2, 7) # åœŸæ›œæ—¥
    offset = (test_date.weekday() + 1) % 7
    if (test_date - timedelta(days=offset)).weekday() != 6:
        check_results.append("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®æ—¥æ›œé–‹å§‹ãƒ­ã‚¸ãƒƒã‚¯ã®ä¸å‚™")
    try:
        if len(re.split(r',', "a,b")) != 2: raise Exception
    except:
        check_results.append("æ­£è¦è¡¨ç¾(re)ã®ä¸å‚™")
    return check_results

# --- 1. è¨­å®š ---
VERSION = "test-v1.0.5"
REPO = "daimilk-lgtm/kondake"
FILE = "menu.csv"
DICT_FILE = "ingredients.csv"
HIST_FILE = "history.csv"
TOKEN = st.secrets.get("GITHUB_TOKEN")

st.set_page_config(page_title="çŒ®ã ã‘", layout="centered", initial_sidebar_state="collapsed")
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@100;300;400&display=swap');
    html, body, [class*="css"], p, div, select, input, label, span { font-family: 'Noto Sans JP', sans-serif !important; font-weight: 300 !important; }
    .main-title { font-weight: 100 !important; font-size: 3rem; text-align: center; margin: 40px 0; letter-spacing: 0.5rem; }
    header[data-testid="stHeader"] { background: transparent !important; color: transparent !important; }
    .shopping-card { background: white; padding: 15px; border-radius: 12px; border: 1px solid #eee; margin-bottom: 10px; }
    .category-label { font-size: 0.8rem; color: #999; border-bottom: 1px solid #f9f9f9; margin-bottom: 5px; }
</style>
""", unsafe_allow_html=True)

if validate_system_integrity():
    st.error("ã‚·ã‚¹ãƒ†ãƒ æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼")
    st.stop()

def get_data(filename):
    try:
        url = f"https://api.github.com/repos/{REPO}/contents/{filename}"
        headers = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3+json"}
        r = requests.get(url, headers=headers)
        if r.status_code == 200:
            raw = base64.b64decode(r.json()["content"]).decode("utf-8-sig")
            return pd.read_csv(io.StringIO(raw)), r.json()["sha"]
    except: pass
    return pd.DataFrame(), None

def save_to_github(df, filename, message, current_sha):
    csv_content = df.to_csv(index=False, encoding="utf-8-sig")
    content_b64 = base64.b64encode(csv_content.encode("utf-8")).decode("utf-8")
    url = f"https://api.github.com/repos/{REPO}/contents/{filename}"
    headers = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3+json"}
    data = {"message": message, "content": content_b64, "sha": current_sha}
    res = requests.put(url, headers=headers, json=data)
    return res.status_code

# --- 2. ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
st.markdown('<h1 class="main-title">çŒ®ã ã‘</h1>', unsafe_allow_html=True)

df_menu, menu_sha = get_data(FILE)
df_hist, hist_sha = get_data(HIST_FILE)
df_dict, _ = get_data(DICT_FILE)

cats = ["ä¸»èœ1", "ä¸»èœ2", "å‰¯èœ1", "å‰¯èœ2", "æ±ç‰©"]
tab_plan, tab_hist, tab_manage = st.tabs(["ğŸ—“ çŒ®ç«‹ä½œæˆ", "ğŸ“œ å±¥æ­´", "âš™ï¸ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç®¡ç†"])

with tab_plan:
    today = datetime.now()
    offset = (today.weekday() + 1) % 7
    start_date = st.date_input("é–‹å§‹æ—¥ï¼ˆæ—¥ï¼‰", value=today - timedelta(days=offset))
    
    weekly_plan = {}
    day_labels = ["æ—¥", "æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ"]
    days_tabs = st.tabs(day_labels)
    
    for i, tab in enumerate(days_tabs):
        target_date = start_date + timedelta(days=i)
        d_str = target_date.strftime("%Y/%m/%d")
        with tab:
            st.markdown(f"##### {d_str} ({day_labels[i]})")
            day_menu = {c: st.selectbox(c, ["ãªã—"] + df_menu[df_menu["ã‚«ãƒ†ã‚´ãƒªãƒ¼"] == c]["æ–™ç†å"].tolist(), key=f"v105_{i}_{c}") for c in cats}
            weekly_plan[d_str] = {"menu": day_menu, "weekday": day_labels[i]}

    memo = st.text_area("ãƒ¡ãƒ¢")

    if st.button("ç¢ºå®šã—ã¦è²·ã„ç‰©ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
        all_ings = []
        new_entries = []
        
        for d_str, data in weekly_plan.items():
            for c_type, dish in data["menu"].items():
                if dish != "ãªã—":
                    # å±¥æ­´ç”¨ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
                    new_entries.append({"æ—¥ä»˜": d_str, "æ›œæ—¥": data["weekday"], "ã‚«ãƒ†ã‚´ãƒªãƒ¼": c_type, "æ–™ç†å": dish})
                    # ææ–™æŠ½å‡º
                    ing_raw = df_menu[df_menu["æ–™ç†å"] == dish]["ææ–™"].iloc[0]
                    items = re.split(r'[,ã€\n]', str(ing_raw))
                    all_ings.extend([x.strip() for x in items if x.strip()])
        
        if new_entries:
            # 1. è²·ã„ç‰©ãƒªã‚¹ãƒˆã®è¡¨ç¤º
            st.markdown("### ğŸ›’ è²·ã„ç‰©ãƒªã‚¹ãƒˆ")
            counts = pd.Series(all_ings + ([m.strip() for m in re.split(r'[,ã€\n]', memo) if m.strip()] if memo else [])).value_counts().reset_index()
            counts.columns = ["name", "count"]
            
            def get_cat(item):
                if df_dict is not None and not df_dict.empty:
                    for _, row in df_dict.iterrows():
                        if row["ææ–™"] in item: return row["ç¨®åˆ¥"]
                return "99æœªåˆ†é¡"
            
            counts["cat"] = counts["name"].apply(get_cat)
            for cat, group in counts.sort_values("cat").groupby("cat"):
                items_html = "".join([f'<div style="font-size:1.1rem; padding:4px 0;">â–¡ {row["name"]} {"Ã— "+str(row["count"]) if row["count"] > 1 else ""}</div>' for _, row in group.iterrows()])
                st.markdown(f'<div class="shopping-card"><div class="category-label">{cat}</div>{items_html}</div>', unsafe_allow_html=True)
            
            # 2. å±¥æ­´ã®ä¿å­˜ã¨å³æ™‚æ›´æ–°
            # ä¿å­˜å‰ã«æœ€æ–°ã®SHAã‚’å–å¾—ï¼ˆã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆé˜²æ­¢ï¼‰
            _, latest_hist_sha = get_data(HIST_FILE)
            updated_hist = pd.concat([df_hist, pd.DataFrame(new_entries)], ignore_index=True).drop_duplicates()
            
            status = save_to_github(updated_hist, HIST_FILE, f"Update history {VERSION}", latest_hist_sha)
            if status == 201 or status == 200:
                st.success("çŒ®ç«‹ã‚’å±¥æ­´ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
                st.cache_data.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¶ˆã—ã¦æ¬¡å›ãƒ­ãƒ¼ãƒ‰æ™‚ã«æœ€æ–°ã‚’èª­ã¿è¾¼ã‚€
            else:
                st.error("å±¥æ­´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

with tab_hist:
    if not df_hist.empty:
        st.dataframe(df_hist.sort_values("æ—¥ä»˜", ascending=False), use_container_width=True, hide_index=True)

with tab_manage:
    # æ—¢å­˜ã®ç®¡ç†ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆçœç•¥ã›ãšç¶­æŒï¼‰
    st.info("ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç®¡ç†ãƒ­ã‚¸ãƒƒã‚¯ç¶­æŒ")

st.markdown(f'<div style="text-align:right; font-size:0.6rem; color:#ddd;">{VERSION}</div>', unsafe_allow_html=True)
